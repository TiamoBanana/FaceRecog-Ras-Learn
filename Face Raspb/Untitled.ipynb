{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c57492fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import sqlite3\n",
    "from PIL import Image\n",
    "\n",
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import *\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.applications import MobileNet\n",
    "from keras.applications import MobileNetV2\n",
    "from keras.applications.mobilenet_v2 import MobileNetV2\n",
    "from keras.applications import VGG16\n",
    "from keras.applications import VGG19\n",
    "\n",
    "import time\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b87f27e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get data\n",
    "path = 'dataset2'\n",
    "\n",
    "def getImageWithId(path):\n",
    "    imagePaths = [os.path.join(path, f) for f in os.listdir(path)]\n",
    "    \n",
    "    faces = []\n",
    "    IDs = []\n",
    "    \n",
    "    for imagePath in imagePaths:\n",
    "        faceImg = Image.open(imagePath).convert('L')\n",
    "        faceNp = np.array(faceImg, 'uint8')\n",
    "        Id = int(imagePath.split('.')[1])\n",
    "        \n",
    "        faces.append(faceNp)\n",
    "        IDs.append(Id)\n",
    "        \n",
    "        cv2.imshow('training', faceNp)\n",
    "        cv2.waitKey(10)\n",
    "    return faces, IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3df5ec7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create train and test\n",
    "faces, Ids = getImageWithId(path)\n",
    "\n",
    "x_train = np.array(faces)\n",
    "y_train = np.array(Ids)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e7e1bc78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "(1000, 256, 256, 1)\n",
      "[[1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1.]]\n",
      "(1000, 5)\n"
     ]
    }
   ],
   "source": [
    "x_train = np.reshape(x_train, (x_train.shape[0], 256, 256, 1)) / 255\n",
    "filenames = os.listdir(\"dataset2\")\n",
    "categories = []\n",
    "\n",
    "for f_name in filenames:\n",
    "    category = f_name.split('.')[1]\n",
    "    if category == '1':\n",
    "        categories.append(0)\n",
    "    elif category == '2':\n",
    "        categories.append(1)\n",
    "    elif category == '3':\n",
    "        categories.append(2)\n",
    "    elif category == '4':\n",
    "        categories.append(3)\n",
    "    elif category == '5':\n",
    "        categories.append(4)\n",
    "    '''elif category == '6':\n",
    "        categories.append(5)\n",
    "    elif category == '7':\n",
    "        categories.append(6)\n",
    "    elif category == '8':\n",
    "        categories.append(7)\n",
    "    elif category == '9':\n",
    "        categories.append(8)'''\n",
    "\n",
    "print(categories[0])\n",
    "print(categories[300])\n",
    "\n",
    "y_train = np_utils.to_categorical(categories, 5)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4c5a2d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1ef123a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_train, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "640b11fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the data generator\n",
    "datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a333e924",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeat the grayscale image to create 3 channels\n",
    "x_train = np.repeat(x_train, 3, axis=3)\n",
    "x_test = np.repeat(x_test, 3, axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fc6efa59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained VGG16 model\n",
    "vgg = VGG16(weights='imagenet', include_top=False, input_shape=(256,256,3))\n",
    "\n",
    "# Freeze the pre-trained layers\n",
    "for layer in vgg.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Create model\n",
    "model = Sequential()\n",
    "model.add(vgg)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.5))  # Add Dropout layer with dropout rate of 0.5\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "'''# Create MobileNet model\n",
    "base_model = MobileNet(weights='imagenet', include_top=False, input_shape=(256, 256, 3))\n",
    "\n",
    "model = Sequential()\n",
    "model.add(base_model)\n",
    "model.add(GlobalAveragePooling2D())\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(5, activation='softmax'))'''\n",
    "\n",
    "'''# Load pre-trained MobileNet model\n",
    "mobilenet = MobileNet(weights='imagenet', include_top=False, input_shape=(256, 256, 3))\n",
    "\n",
    "# Freeze the pre-trained layers\n",
    "for layer in mobilenet.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Create model\n",
    "model = Sequential()\n",
    "model.add(mobilenet)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.5))  # Add Dropout layer with dropout rate of 0.5\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))  # Add Dropout layer with dropout rate of 0.5\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "mobilenet = MobileNetV2(weights='imagenet', include_top=False, input_shape=(256, 256, 3))\n",
    "\n",
    "\n",
    "for layer in mobilenet.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "model = Sequential()\n",
    "model.add(mobilenet)\n",
    "model.add(GlobalAveragePooling2D())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))  # Add Dropout layer with dropout rate of 0.5\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))  # Add Dropout layer with dropout rate of 0.5\n",
    "model.add(Dense(9, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])'''\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4e247f05",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " vgg16 (Functional)          (None, 8, 8, 512)         14714688  \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 32768)             0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1024)              33555456  \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 512)               524800    \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 5)                 2565      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 48,797,509\n",
      "Trainable params: 34,082,821\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "02e92072",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "80/80 [==============================] - 236s 3s/step - loss: 1.2537 - accuracy: 0.8712 - val_loss: 0.2622 - val_accuracy: 0.9650\n",
      "Epoch 2/20\n",
      "80/80 [==============================] - 237s 3s/step - loss: 0.0949 - accuracy: 0.9837 - val_loss: 5.5708e-04 - val_accuracy: 1.0000\n",
      "Epoch 3/20\n",
      "80/80 [==============================] - 236s 3s/step - loss: 0.0802 - accuracy: 0.9800 - val_loss: 0.0508 - val_accuracy: 0.9850\n",
      "Epoch 4/20\n",
      "80/80 [==============================] - 236s 3s/step - loss: 0.0272 - accuracy: 0.9937 - val_loss: 0.0046 - val_accuracy: 0.9950\n",
      "Epoch 5/20\n",
      "80/80 [==============================] - 236s 3s/step - loss: 6.4354e-04 - accuracy: 1.0000 - val_loss: 3.6358e-07 - val_accuracy: 1.0000\n",
      "Epoch 6/20\n",
      "80/80 [==============================] - 236s 3s/step - loss: 0.0040 - accuracy: 0.9987 - val_loss: 4.0275e-05 - val_accuracy: 1.0000\n",
      "Epoch 7/20\n",
      "80/80 [==============================] - 236s 3s/step - loss: 7.1840e-05 - accuracy: 1.0000 - val_loss: 4.9709e-05 - val_accuracy: 1.0000\n",
      "Epoch 8/20\n",
      "80/80 [==============================] - 236s 3s/step - loss: 1.9458e-06 - accuracy: 1.0000 - val_loss: 4.8142e-05 - val_accuracy: 1.0000\n",
      "Epoch 9/20\n",
      "80/80 [==============================] - 236s 3s/step - loss: 2.4088e-05 - accuracy: 1.0000 - val_loss: 4.1574e-05 - val_accuracy: 1.0000\n",
      "Epoch 10/20\n",
      "80/80 [==============================] - 236s 3s/step - loss: 0.0252 - accuracy: 0.9962 - val_loss: 1.0561e-06 - val_accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "80/80 [==============================] - 236s 3s/step - loss: 0.2599 - accuracy: 0.9712 - val_loss: 0.0064 - val_accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "80/80 [==============================] - 236s 3s/step - loss: 0.0429 - accuracy: 0.9950 - val_loss: 1.3408e-05 - val_accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "80/80 [==============================] - 225s 3s/step - loss: 0.1645 - accuracy: 0.9850 - val_loss: 2.2931e-05 - val_accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "80/80 [==============================] - 218s 3s/step - loss: 0.0410 - accuracy: 0.9950 - val_loss: 0.0933 - val_accuracy: 0.9850\n",
      "Epoch 15/20\n",
      "80/80 [==============================] - 216s 3s/step - loss: 0.0964 - accuracy: 0.9900 - val_loss: 0.0248 - val_accuracy: 0.9900\n",
      "Epoch 16/20\n",
      "80/80 [==============================] - 216s 3s/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "80/80 [==============================] - 216s 3s/step - loss: 0.0115 - accuracy: 0.9975 - val_loss: 5.3644e-09 - val_accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "80/80 [==============================] - 218s 3s/step - loss: 5.0216e-08 - accuracy: 1.0000 - val_loss: 1.1325e-08 - val_accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "80/80 [==============================] - 216s 3s/step - loss: 1.2368e-08 - accuracy: 1.0000 - val_loss: 1.0133e-08 - val_accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "80/80 [==============================] - 218s 3s/step - loss: 4.4703e-10 - accuracy: 1.0000 - val_loss: 1.0133e-08 - val_accuracy: 1.0000\n",
      "7/7 [==============================] - 43s 6s/step - loss: 1.0133e-08 - accuracy: 1.0000\n",
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Train the model with augmented data\n",
    "start_time = time.time()\n",
    "history = model.fit(x_train, y_train, batch_size=10, epochs=20, validation_data=(x_test, y_test))\n",
    "end_time = time.time()\n",
    "training_time = end_time - start_time\n",
    "\n",
    "# Đánh giá độ chính xác\n",
    "_, accuracy = model.evaluate(x_test, y_test)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Ghi ra file\n",
    "with open(\"training_log.txt\", \"w\") as f:\n",
    "    f.write(\"Accuracy: {}\\n\".format(accuracy))\n",
    "    f.write(\"Training Time: {} seconds\\n\".format(training_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8be4908f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('face_transfer_vgg16_5_200.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1fa141e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained VGG19 model\n",
    "vgg = VGG19(weights='imagenet', include_top=False, input_shape=(256, 256, 3))\n",
    "\n",
    "# Freeze the pre-trained layers\n",
    "for layer in vgg.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Create model\n",
    "model = Sequential()\n",
    "model.add(vgg)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))  # Add Dropout layer with dropout rate of 0.5\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9d2bc7b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "80/80 [==============================] - 238s 3s/step - loss: 0.6671 - accuracy: 0.8450 - val_loss: 0.0131 - val_accuracy: 0.9900\n",
      "Epoch 2/20\n",
      "80/80 [==============================] - 250s 3s/step - loss: 0.0330 - accuracy: 0.9887 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
      "Epoch 3/20\n",
      "80/80 [==============================] - 258s 3s/step - loss: 0.0593 - accuracy: 0.9800 - val_loss: 0.0071 - val_accuracy: 1.0000\n",
      "Epoch 4/20\n",
      "80/80 [==============================] - 250s 3s/step - loss: 0.0537 - accuracy: 0.9800 - val_loss: 0.0074 - val_accuracy: 0.9950\n",
      "Epoch 5/20\n",
      "80/80 [==============================] - 257s 3s/step - loss: 0.0322 - accuracy: 0.9900 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
      "Epoch 6/20\n",
      "80/80 [==============================] - 262s 3s/step - loss: 0.0097 - accuracy: 0.9987 - val_loss: 4.2870e-05 - val_accuracy: 1.0000\n",
      "Epoch 7/20\n",
      "80/80 [==============================] - 250s 3s/step - loss: 0.0179 - accuracy: 0.9912 - val_loss: 1.0085e-05 - val_accuracy: 1.0000\n",
      "Epoch 8/20\n",
      "80/80 [==============================] - 251s 3s/step - loss: 0.0061 - accuracy: 0.9975 - val_loss: 7.3994e-04 - val_accuracy: 1.0000\n",
      "Epoch 9/20\n",
      "80/80 [==============================] - 254s 3s/step - loss: 0.0120 - accuracy: 0.9950 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "Epoch 10/20\n",
      "80/80 [==============================] - 260s 3s/step - loss: 0.0344 - accuracy: 0.9887 - val_loss: 3.2448e-06 - val_accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "80/80 [==============================] - 250s 3s/step - loss: 0.0173 - accuracy: 0.9937 - val_loss: 1.1268e-04 - val_accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "80/80 [==============================] - 252s 3s/step - loss: 0.0102 - accuracy: 0.9975 - val_loss: 2.0030e-05 - val_accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "80/80 [==============================] - 256s 3s/step - loss: 0.0591 - accuracy: 0.9875 - val_loss: 6.7708e-07 - val_accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "80/80 [==============================] - 251s 3s/step - loss: 0.0242 - accuracy: 0.9962 - val_loss: 4.5059e-06 - val_accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "80/80 [==============================] - 249s 3s/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 4.4231e-05 - val_accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "80/80 [==============================] - 246s 3s/step - loss: 1.0456e-04 - accuracy: 1.0000 - val_loss: 5.1139e-05 - val_accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "80/80 [==============================] - 244s 3s/step - loss: 3.2319e-05 - accuracy: 1.0000 - val_loss: 1.0697e-05 - val_accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "80/80 [==============================] - 249s 3s/step - loss: 1.4491e-04 - accuracy: 1.0000 - val_loss: 2.5868e-07 - val_accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "80/80 [==============================] - 244s 3s/step - loss: 4.2895e-05 - accuracy: 1.0000 - val_loss: 2.1696e-07 - val_accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "80/80 [==============================] - 249s 3s/step - loss: 1.5902e-05 - accuracy: 1.0000 - val_loss: 1.8298e-07 - val_accuracy: 1.0000\n",
      "7/7 [==============================] - 47s 7s/step - loss: 1.8298e-07 - accuracy: 1.0000\n",
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Train the model with augmented data\n",
    "start_time = time.time()\n",
    "history = model.fit(x_train, y_train, batch_size=10, epochs=20, validation_data=(x_test, y_test))\n",
    "end_time = time.time()\n",
    "training_time = end_time - start_time\n",
    "\n",
    "# Đánh giá độ chính xác\n",
    "_, accuracy = model.evaluate(x_test, y_test)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Ghi ra file\n",
    "with open(\"training_log_vgg19.txt\", \"w\") as f:\n",
    "    f.write(\"Accuracy: {}\\n\".format(accuracy))\n",
    "    f.write(\"Training Time: {} seconds\\n\".format(training_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4a4f7931",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('face_transfer_vgg19.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca910181",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 400ms/step\n",
      "1.0\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1.0\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "1.0\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1.0\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1.0\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1.0\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1.0\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1.0\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1.0\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1.0\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1.0\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1.0\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1.0\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1.0\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1.0\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1.0\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1.0\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1.0\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1.0\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1.0\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1.0\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1.0\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1.0\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1.0\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1.0\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1.0\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1.0\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1.0\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1.0\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1.0\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1.0\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1.0\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1.0\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1.0\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1.0\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1.0\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1.0\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1.0\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1.0\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1.0\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1.0\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1.0\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1.0\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1.0\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1.0\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1.0\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1.0\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1.0\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1.0\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1.0\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1.0\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1.0\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1.0\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1.0\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1.0\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1.0\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1.0\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1.0\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1.0\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1.0\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1.0\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1.0\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1.0\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1.0\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1.0\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1.0\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1.0\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1.0\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1.0\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1.0\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "0.9999993\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1.0\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1.0\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1.0\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1.0\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1.0\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1.0\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1.0\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1.0\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1.0\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1.0\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1.0\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1.0\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1.0\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1.0\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1.0\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1.0\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1.0\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1.0\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1.0\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1.0\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1.0\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "import cv2\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "\n",
    "model = load_model('Face_5_txt_mobilenet.h5')\n",
    "face_cascade = cv2.CascadeClassifier(cv2.samples.findFile(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml'))\n",
    "\n",
    "def getProfile(id):\n",
    "    conn = sqlite3.connect('data.db')\n",
    "    query = \"SELECT * FROM people WHERE ID =\" + str(id)\n",
    "    cursor = conn.execute(query)\n",
    "    profile = None\n",
    "    for row in cursor:\n",
    "        profile = row\n",
    "    conn.close()\n",
    "    return profile\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "fontface = cv2.FONT_HERSHEY_SIMPLEX\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    faces = face_cascade.detectMultiScale(gray, minSize=(100, 100))\n",
    "    \n",
    "    for (x, y, w, h) in faces:\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "        roi_gray = cv2.resize(gray[y: y + h, x: x + w], (256, 256))\n",
    "        test = np.expand_dims(roi_gray, axis=-1)\n",
    "        test = np.concatenate((test, test, test), axis=-1)\n",
    "        test = np.expand_dims(test, axis=0) / 255.0\n",
    "        t = model.predict(test)\n",
    "        t = t.reshape(5,)\n",
    "        print(t[np.argmax(t)])\n",
    "        id = np.argmax(t) + 1\n",
    "        profile = getProfile(id)\n",
    "        if t[np.argmax(t)] > 0.99:\n",
    "            if profile is not None:\n",
    "                cv2.putText(frame, str(profile[1]), (x + 10, y + h + 30), fontface, 1, (0, 255, 0), 2)\n",
    "        else:\n",
    "            cv2.putText(frame, \"Unknown\", (x + 10, y + h + 30), fontface, 1, (0, 255, 0), 2)\n",
    "    \n",
    "    cv2.imshow('image', frame)\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a4b707",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
